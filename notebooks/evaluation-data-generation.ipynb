{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6606bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "import json\n",
    "import re\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c7c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 1. Load data and add missing 'id'\n",
    "# -------------------------------------------------\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.reset_index(drop=True)           # make sure index is clean\n",
    "df['id'] = df.index                       # â† adds id 0, 1, 2, ..., 199\n",
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76534f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 2. Robust JSON extraction function\n",
    "# -------------------------------------------------\n",
    "def safe_json_extract(text):\n",
    "    \"\"\"Extracts a valid {\"questions\": [...]} dict even if model is messy\"\"\"\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Try direct json load first (fast path)\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    \n",
    "    # Fallback 1: look for JSON inside markdown ```json ... ```\n",
    "    json_match = re.search(r\"```(?:json)?\\s*({.*?})\\s*```\", text, re.DOTALL)\n",
    "    if json_match:\n",
    "        try:\n",
    "            return json.loads(json_match.group(1))\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    \n",
    "    # Fallback 2: extract anything that looks like [\"...\", \"...\"]\n",
    "    list_match = re.search(r'\\[\\s*(?:\"[^\"]*\"(?:\\s*,\\s*\"[^\"]*\")*)\\s*\\]', text)\n",
    "    if list_match:\n",
    "        try:\n",
    "            questions_list = json.loads(list_match.group(0))\n",
    "            return {\"questions\": questions_list}\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    \n",
    "    # Last resort: split by quotes (very permissive)\n",
    "    questions = re.findall(r'\"([^\"]{10,})\"', text)  # at least 10 chars to avoid garbage\n",
    "    if len(questions) >= 3:  # we need at least ~5 questions\n",
    "        return {\"questions\": questions[:5]}\n",
    "    \n",
    "    raise ValueError(f\"Could not extract questions from: {text[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c79759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate a user of our nutrition assistant application.\n",
    "Formulate 5 questions this user might ask based on a provided recipe.\n",
    "Make the questions specific to this recipe.\n",
    "The record should contain the answer to the questions, and the questions should\n",
    "be complete and not too short. Use as fewer words as possible from the record. \n",
    "\n",
    "The record:\n",
    "\n",
    "recipe_name: {recipe_name}\n",
    "meal_type: {meal_type}\n",
    "dietary_category: {dietary_category}\n",
    "ingredients: {ingredients}\n",
    "equipment_needed: {equipment_needed}\n",
    "nutritional_information: {nutritional_information}\n",
    "instructions: {instructions}\n",
    "allergens: {allergens}\n",
    "prep_time_minutes: {prep_time_minutes}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "{{\"questions\": [\"question1\", \"question2\", ..., \"question5\"]}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c9b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 3. Generate questions safely\n",
    "# -------------------------------------------------\n",
    "def generate_questions(doc):\n",
    "    prompt = prompt_template.format(**doc)\n",
    "    response = ollama.chat(\n",
    "        model='qwen2:1.5b',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    raw = response['message']['content']\n",
    "    return safe_json_extract(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c6d0cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5829c6e27adb45ce8ab562748f743adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating questions:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed on doc 60: 'questions'\n",
      "\n",
      "Failed on doc 94: 'questions'\n",
      "\n",
      "Failed on doc 108: list indices must be integers or slices, not str\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 4. Main loop (now 100% safe)\n",
    "# -------------------------------------------------\n",
    "results = {}\n",
    "\n",
    "for doc in tqdm(documents, desc=\"Generating questions\"):\n",
    "    doc_id = doc['id']\n",
    "    \n",
    "    if doc_id in results:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        parsed = generate_questions(doc)\n",
    "        results[doc_id] = parsed[\"questions\"]\n",
    "    except Exception as e:\n",
    "        print(f\"\\nFailed on doc {doc_id}: {e}\")\n",
    "        results[doc_id] = []  # or skip / retry later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be493d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Generated 807 question-document pairs.\n",
      "Saved to ground-truth-retrieval.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 5. Save ground-truth file\n",
    "# -------------------------------------------------\n",
    "final_results = []\n",
    "for doc_id, questions in results.items():\n",
    "    for q in questions:\n",
    "        final_results.append((doc_id, q))\n",
    "\n",
    "df_results = pd.DataFrame(final_results, columns=['id', 'question'])\n",
    "df_results.to_csv('ground-truth-retrieval.csv', index=False)\n",
    "\n",
    "print(f\"Done! Generated {len(final_results)} question-document pairs.\")\n",
    "print(\"Saved to ground-truth-retrieval.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "h8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
